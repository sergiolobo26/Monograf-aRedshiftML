
Importing BGS data, generating the fluxes array


computing Log Flux, Log Alpha

Generating train-test set for 10 data points 

Scaling data 

# Tuning hyper-parameters for r2

Fitting model with n_jobs = 4


Best parameters set found on development set:

{'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.01}

Grid scores on development set:

-1.844 (+/-6.067) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 0.1}
-1.572 (+/-5.218) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 0.1}
0.130 (+/-1.723) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 0.1}
0.372 (+/-1.083) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.1}
0.748 (+/-0.706) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.1}
0.767 (+/-0.323) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 0.1}
-0.104 (+/-1.330) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 0.1}
-70.717 (+/-137.012) for {'kernel': 'poly', 'gamma': 1, 'alpha': 0.1}
0.107 (+/-1.313) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 0.01}
0.373 (+/-0.903) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 0.01}
0.912 (+/-0.122) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 0.01}
0.929 (+/-0.031) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.01}
0.858 (+/-0.240) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.01}
0.863 (+/-0.229) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 0.01}
0.155 (+/-0.812) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 0.01}
-79.077 (+/-157.715) for {'kernel': 'poly', 'gamma': 1, 'alpha': 0.01}
-3.514 (+/-12.247) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 1}
-3.488 (+/-12.124) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 1}
-2.355 (+/-9.242) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 1}
-2.179 (+/-8.371) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 1}
-0.912 (+/-5.863) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 1}
0.000 (+/-1.955) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 1}
-2.496 (+/-8.668) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 1}
-43.897 (+/-72.943) for {'kernel': 'poly', 'gamma': 1, 'alpha': 1}

r2 score computed on the full evaluation set:

0.67475920037

-----Done for n = 10-----
Generating train-test set for 100 data points 

Scaling data 

# Tuning hyper-parameters for r2

Fitting model with n_jobs = 4


Best parameters set found on development set:

{'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.1}

Grid scores on development set:

0.776 (+/-0.110) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 0.1}
0.837 (+/-0.080) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 0.1}
0.927 (+/-0.103) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 0.1}
0.928 (+/-0.128) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.1}
0.940 (+/-0.080) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.1}
0.917 (+/-0.166) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 0.1}
0.770 (+/-0.269) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 0.1}
0.906 (+/-0.180) for {'kernel': 'poly', 'gamma': 1, 'alpha': 0.1}
0.929 (+/-0.114) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 0.01}
0.932 (+/-0.124) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 0.01}
0.933 (+/-0.131) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 0.01}
0.929 (+/-0.148) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.01}
0.938 (+/-0.114) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.01}
0.912 (+/-0.154) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 0.01}
0.802 (+/-0.248) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 0.01}
0.913 (+/-0.156) for {'kernel': 'poly', 'gamma': 1, 'alpha': 0.01}
0.192 (+/-0.210) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 1}
0.288 (+/-0.211) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 1}
0.757 (+/-0.157) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 1}
0.834 (+/-0.088) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 1}
0.883 (+/-0.109) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 1}
0.894 (+/-0.204) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 1}
0.440 (+/-0.375) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 1}
0.849 (+/-0.275) for {'kernel': 'poly', 'gamma': 1, 'alpha': 1}

r2 score computed on the full evaluation set:

0.981857888286

-----Done for n = 100-----
Generating train-test set for 10 data points 

Scaling data 

# Tuning hyper-parameters for r2

Fitting model with n_jobs = 4


Best parameters set found on development set:

{'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.01}

Grid scores on development set:

-1.844 (+/-6.067) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 0.1}
-1.572 (+/-5.218) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 0.1}
0.130 (+/-1.723) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 0.1}
0.372 (+/-1.083) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.1}
0.748 (+/-0.706) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.1}
0.767 (+/-0.323) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 0.1}
-0.104 (+/-1.330) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 0.1}
-70.717 (+/-137.012) for {'kernel': 'poly', 'gamma': 1, 'alpha': 0.1}
0.107 (+/-1.313) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 0.01}
0.373 (+/-0.903) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 0.01}
0.912 (+/-0.122) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 0.01}
0.929 (+/-0.031) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.01}
0.858 (+/-0.240) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.01}
0.863 (+/-0.229) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 0.01}
0.155 (+/-0.812) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 0.01}
-79.077 (+/-157.715) for {'kernel': 'poly', 'gamma': 1, 'alpha': 0.01}
-3.514 (+/-12.247) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 1}
-3.488 (+/-12.124) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 1}
-2.355 (+/-9.242) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 1}
-2.179 (+/-8.371) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 1}
-0.912 (+/-5.863) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 1}
0.000 (+/-1.955) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 1}
-2.496 (+/-8.668) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 1}
-43.897 (+/-72.943) for {'kernel': 'poly', 'gamma': 1, 'alpha': 1}

r2 score computed on the full evaluation set:

0.67475920037

-----Done for n = 10-----
Generating train-test set for 100 data points 

Scaling data 

# Tuning hyper-parameters for r2

Fitting model with n_jobs = 4


Best parameters set found on development set:

{'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.1}

Grid scores on development set:

0.776 (+/-0.110) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 0.1}
0.837 (+/-0.080) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 0.1}
0.927 (+/-0.103) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 0.1}
0.928 (+/-0.128) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.1}
0.940 (+/-0.080) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.1}
0.917 (+/-0.166) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 0.1}
0.770 (+/-0.269) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 0.1}
0.906 (+/-0.180) for {'kernel': 'poly', 'gamma': 1, 'alpha': 0.1}
0.929 (+/-0.114) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 0.01}
0.932 (+/-0.124) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 0.01}
0.933 (+/-0.131) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 0.01}
0.929 (+/-0.148) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.01}
0.938 (+/-0.114) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.01}
0.912 (+/-0.154) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 0.01}
0.802 (+/-0.248) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 0.01}
0.913 (+/-0.156) for {'kernel': 'poly', 'gamma': 1, 'alpha': 0.01}
0.192 (+/-0.210) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 1}
0.288 (+/-0.211) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 1}
0.757 (+/-0.157) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 1}
0.834 (+/-0.088) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 1}
0.883 (+/-0.109) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 1}
0.894 (+/-0.204) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 1}
0.440 (+/-0.375) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 1}
0.849 (+/-0.275) for {'kernel': 'poly', 'gamma': 1, 'alpha': 1}

r2 score computed on the full evaluation set:

0.981857888286

-----Done for n = 100-----
Generating train-test set for 10 data points 

Scaling data 

# Tuning hyper-parameters for r2

Fitting model with n_jobs = 4


Best parameters set found on development set:

{'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.01}

Grid scores on development set:

-1.844 (+/-6.067) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 0.1}
-1.572 (+/-5.218) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 0.1}
0.130 (+/-1.723) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 0.1}
0.372 (+/-1.083) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.1}
0.748 (+/-0.706) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.1}
0.767 (+/-0.323) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 0.1}
-0.104 (+/-1.330) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 0.1}
-70.717 (+/-137.012) for {'kernel': 'poly', 'gamma': 1, 'alpha': 0.1}
0.107 (+/-1.313) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 0.01}
0.373 (+/-0.903) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 0.01}
0.912 (+/-0.122) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 0.01}
0.929 (+/-0.031) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.01}
0.858 (+/-0.240) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.01}
0.863 (+/-0.229) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 0.01}
0.155 (+/-0.812) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 0.01}
-79.077 (+/-157.715) for {'kernel': 'poly', 'gamma': 1, 'alpha': 0.01}
-3.514 (+/-12.247) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 1}
-3.488 (+/-12.124) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 1}
-2.355 (+/-9.242) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 1}
-2.179 (+/-8.371) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 1}
-0.912 (+/-5.863) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 1}
0.000 (+/-1.955) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 1}
-2.496 (+/-8.668) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 1}
-43.897 (+/-72.943) for {'kernel': 'poly', 'gamma': 1, 'alpha': 1}

r2 score computed on the full evaluation set:

0.67475920037

-----Done for n = 10-----
Generating train-test set for 100 data points 

Scaling data 

# Tuning hyper-parameters for r2

Fitting model with n_jobs = 4


Best parameters set found on development set:

{'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.1}

Grid scores on development set:

0.776 (+/-0.110) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 0.1}
0.837 (+/-0.080) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 0.1}
0.927 (+/-0.103) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 0.1}
0.928 (+/-0.128) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.1}
0.940 (+/-0.080) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.1}
0.917 (+/-0.166) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 0.1}
0.770 (+/-0.269) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 0.1}
0.906 (+/-0.180) for {'kernel': 'poly', 'gamma': 1, 'alpha': 0.1}
0.929 (+/-0.114) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 0.01}
0.932 (+/-0.124) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 0.01}
0.933 (+/-0.131) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 0.01}
0.929 (+/-0.148) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 0.01}
0.938 (+/-0.114) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 0.01}
0.912 (+/-0.154) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 0.01}
0.802 (+/-0.248) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 0.01}
0.913 (+/-0.156) for {'kernel': 'poly', 'gamma': 1, 'alpha': 0.01}
0.192 (+/-0.210) for {'kernel': 'rbf', 'gamma': 0.001, 'alpha': 1}
0.288 (+/-0.211) for {'kernel': 'poly', 'gamma': 0.001, 'alpha': 1}
0.757 (+/-0.157) for {'kernel': 'rbf', 'gamma': 0.01, 'alpha': 1}
0.834 (+/-0.088) for {'kernel': 'poly', 'gamma': 0.01, 'alpha': 1}
0.883 (+/-0.109) for {'kernel': 'rbf', 'gamma': 0.1, 'alpha': 1}
0.894 (+/-0.204) for {'kernel': 'poly', 'gamma': 0.1, 'alpha': 1}
0.440 (+/-0.375) for {'kernel': 'rbf', 'gamma': 1, 'alpha': 1}
0.849 (+/-0.275) for {'kernel': 'poly', 'gamma': 1, 'alpha': 1}

r2 score computed on the full evaluation set:

0.981857888286

-----Done for n = 100-----

-----------------------------------Results--------------------------------------------
Time results after 3 repetitions, n_jobs = 4
n_datos:  [10, 100]

fit_time mean:  [  0.1802  10.3574]
fit_time error:  [ 0.0064  0.4902] 

predict_time mean:  [ 0.0002  0.0004]
predict_time error:  [  3.9004e-06   3.4841e-06] 

Total run time: 40.30 s
------------------------------------ Done --------------------------------------------
